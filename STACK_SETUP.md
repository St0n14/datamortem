# Guide de dÃ©marrage de la stack complÃ¨te dataMortem

Ce guide explique comment dÃ©marrer toute la stack dataMortem avec OpenSearch intÃ©grÃ©.

## ğŸ¯ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FRONTEND (React)                      â”‚
â”‚                   http://localhost:5174                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚ REST API
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    API FastAPI                           â”‚
â”‚                   http://localhost:8000                  â”‚
â””â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â”‚             â”‚             â”‚             â”‚
  â–¼             â–¼             â–¼             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚PostgreSQLâ”‚ â”‚Redis â”‚   â”‚ OpenSearch  â”‚ â”‚   Celery   â”‚
â”‚  :5432  â”‚ â”‚:6379 â”‚   â”‚    :9200    â”‚ â”‚   Worker   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‹ PrÃ©requis

- **Docker** et **Docker Compose**
- **Python 3.10+** avec **uv** installÃ©
- **Node.js 18+** et **npm**
- **PostgreSQL client** (psql) - optionnel pour debug

## ğŸš€ DÃ©marrage rapide (automatique)

### Option 1: Script tout-en-un

```bash
# Rendre le script exÃ©cutable
chmod +x start-stack.sh

# DÃ©marrer toute la stack
./start-stack.sh
```

Ce script va automatiquement:
1. âœ… DÃ©marrer PostgreSQL, Redis, OpenSearch (Docker)
2. âœ… CrÃ©er la base de donnÃ©es
3. âœ… DÃ©marrer Celery Worker
4. âœ… DÃ©marrer l'API FastAPI
5. âœ… DÃ©marrer le Frontend React

**ArrÃªter la stack:**
```bash
./stop-stack.sh
```

---

## ğŸ”§ DÃ©marrage manuel (Ã©tape par Ã©tape)

### Ã‰TAPE 1: DÃ©marrer les services Docker

```bash
# DÃ©marre PostgreSQL, Redis, OpenSearch, Dashboards
docker-compose up -d

# VÃ©rifier que tous les services sont UP
docker-compose ps
```

Attendez ~30 secondes que OpenSearch dÃ©marre.

**VÃ©rifications:**
```bash
# PostgreSQL
docker exec datamortem-postgres pg_isready -U datamortem

# Redis
docker exec datamortem-redis redis-cli ping

# OpenSearch
curl http://localhost:9200
```

---

### Ã‰TAPE 2: Configuration de l'API

Le fichier `.env` est dÃ©jÃ  configurÃ© pour utiliser la stack Docker:

```bash
cat services/api/.env
```

Devrait contenir:
```env
DM_ENV=development
DM_DB_URL=postgresql://datamortem:datamortem_dev_password@localhost:5432/datamortem
DM_CELERY_BROKER=redis://localhost:6379/0
DM_CELERY_BACKEND=redis://localhost:6379/1
DM_OPENSEARCH_HOST=localhost
DM_OPENSEARCH_PORT=9200
...
```

---

### Ã‰TAPE 3: Installer les dÃ©pendances Python

```bash
cd services/api
uv sync
```

---

### Ã‰TAPE 4: CrÃ©er la base de donnÃ©es

```bash
cd services/api

# CrÃ©er les tables via SQLAlchemy
uv run python -c "from app.db import Base, engine; Base.metadata.create_all(bind=engine)"

# OU via Alembic si configurÃ©
# uv run alembic upgrade head
```

**VÃ©rification:**
```bash
# Connexion Ã  PostgreSQL
docker exec -it datamortem-postgres psql -U datamortem -d datamortem

# Lister les tables
\dt

# Quitter
\q
```

---

### Ã‰TAPE 5: DÃ©marrer Celery Worker

**Terminal 1 - Celery Worker:**
```bash
cd services/api
uv run celery -A app.celery_app worker --loglevel=info
```

Vous devriez voir:
```
-------------- celery@hostname v5.4.0
---- **** -----
...
[tasks]
  . app.tasks.index_results.bulk_index_case_results
  . app.tasks.index_results.index_results_task
  . app.tasks.parse_mft.parse_mft_task
```

---

### Ã‰TAPE 6: DÃ©marrer l'API FastAPI

**Terminal 2 - API:**
```bash
cd services/api
uv run uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```

**VÃ©rification:**
```bash
# Health check
curl http://localhost:8000/health

# OpenSearch health
curl http://localhost:8000/api/search/health

# Swagger UI
open http://localhost:8000/docs
```

---

### Ã‰TAPE 7: DÃ©marrer le Frontend

**Terminal 3 - Frontend:**
```bash
cd frontend

# Installer les dÃ©pendances (premiÃ¨re fois)
npm install

# DÃ©marrer le dev server
npm run dev
```

Le frontend sera accessible sur **http://localhost:5174**

---

## ğŸ§ª Tester l'intÃ©gration complÃ¨te

### 1. CrÃ©er un case de test

```bash
curl -X POST http://localhost:8000/api/cases \
  -H "Content-Type: application/json" \
  -d '{
    "case_id": "case_demo_001",
    "note": "Case de dÃ©monstration OpenSearch"
  }'
```

### 2. CrÃ©er une evidence (fictive)

```bash
curl -X POST http://localhost:8000/api/evidence \
  -H "Content-Type: application/json" \
  -d '{
    "evidence_uid": "evidence_demo_001",
    "case_id": "case_demo_001",
    "local_path": "/tmp/dummy.raw"
  }'
```

### 3. Simuler un parsing (crÃ©er des donnÃ©es de test)

```bash
cd services/api
python test_opensearch.py
```

### 4. DÃ©clencher l'indexation depuis l'API

Supposons que vous avez un TaskRun avec id=1:

```bash
curl -X POST http://localhost:8000/api/indexing/task-run \
  -H "Content-Type: application/json" \
  -d '{
    "task_run_id": 1
  }'
```

### 5. Rechercher dans OpenSearch

```bash
curl -X POST http://localhost:8000/api/search/query \
  -H "Content-Type: application/json" \
  -d '{
    "query": "*",
    "case_id": "test_case_001",
    "size": 10
  }' | jq
```

### 6. Voir le rÃ©sumÃ© d'indexation d'un case

```bash
curl http://localhost:8000/api/indexing/case/test_case_001/summary | jq
```

---

## ğŸ¨ Frontend - DÃ©clencher l'indexation depuis l'UI

Les nouveaux endpoints disponibles pour le frontend:

### Endpoint: Indexer un TaskRun spÃ©cifique

```typescript
// POST /api/indexing/task-run
const response = await fetch('http://localhost:8000/api/indexing/task-run', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({ task_run_id: 123 })
});

const result = await response.json();
// { status: "triggered", message: "...", celery_task_id: "..." }
```

### Endpoint: Indexer tout un case

```typescript
// POST /api/indexing/case
const response = await fetch('http://localhost:8000/api/indexing/case', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    case_id: "case_123",
    force_reindex: false
  })
});
```

### Endpoint: Voir le rÃ©sumÃ© d'indexation

```typescript
// GET /api/indexing/case/{case_id}/summary
const response = await fetch(
  'http://localhost:8000/api/indexing/case/case_123/summary'
);

const summary = await response.json();
/*
{
  case_id: "case_123",
  task_runs: {
    total: 10,
    success: 8,
    indexable: 8
  },
  opensearch: {
    document_count: 15420,
    index_name: "datamortem-case-case_123"
  }
}
*/
```

### Endpoint: Rechercher

```typescript
// POST /api/search/query
const response = await fetch('http://localhost:8000/api/search/query', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    query: "svchost.exe",
    case_id: "case_123",
    from: 0,
    size: 50
  })
});

const results = await response.json();
/*
{
  hits: [...],      // Documents trouvÃ©s
  total: 42,        // Total de rÃ©sultats
  took: 15          // Temps de recherche (ms)
}
*/
```

---

## ğŸ“Š Interfaces disponibles

| Service | URL | Description |
|---------|-----|-------------|
| **Frontend** | http://localhost:5174 | Interface React |
| **API** | http://localhost:8000 | API FastAPI |
| **API Docs** | http://localhost:8000/docs | Swagger UI |
| **OpenSearch** | http://localhost:9200 | API OpenSearch |
| **OpenSearch Dashboards** | http://localhost:5601 | Interface de visualisation |
| **PostgreSQL** | localhost:5432 | Base de donnÃ©es |
| **Redis** | localhost:6379 | Broker Celery |

---

## ğŸ› Troubleshooting

### ProblÃ¨me: "Connection refused" PostgreSQL

```bash
# VÃ©rifier que PostgreSQL est up
docker logs datamortem-postgres

# RedÃ©marrer
docker-compose restart postgres
```

### ProblÃ¨me: Celery ne reÃ§oit pas les tÃ¢ches

```bash
# VÃ©rifier Redis
docker exec datamortem-redis redis-cli ping

# VÃ©rifier la configuration
cd services/api
uv run python -c "from app.config import settings; print(settings.dm_celery_broker)"

# Devrait afficher: redis://localhost:6379/0
```

### ProblÃ¨me: OpenSearch ne dÃ©marre pas

```bash
# VÃ©rifier les logs
docker logs datamortem-opensearch

# VÃ©rifier la mÃ©moire allouÃ©e
docker stats datamortem-opensearch

# Augmenter la mÃ©moire si besoin (modifier docker-compose.yml)
# OPENSEARCH_JAVA_OPTS=-Xms1g -Xmx1g
```

### ProblÃ¨me: API ne se connecte pas Ã  OpenSearch

```bash
# Tester depuis l'API
cd services/api
uv run python -c "
from app.opensearch.client import get_opensearch_client, test_connection
from app.config import settings
client = get_opensearch_client(settings)
print(test_connection(client))
"
```

---

## ğŸ“ Logs

Les logs sont dans le rÃ©pertoire `logs/`:

```bash
# API
tail -f logs/api.log

# Celery Worker
tail -f logs/celery-worker.log

# Frontend
tail -f logs/frontend.log

# Docker services
docker-compose logs -f opensearch
docker-compose logs -f postgres
docker-compose logs -f redis
```

---

## ğŸ”„ Workflow complet

1. **L'utilisateur crÃ©e un case** via le frontend
2. **L'utilisateur upload une evidence** (image disque)
3. **L'utilisateur lance des parsers** (MFT, Prefetch, Registry...)
4. **Les parsers s'exÃ©cutent via Celery** et produisent des rÃ©sultats (CSV/Parquet)
5. **L'utilisateur clique sur "Indexer"** dans le frontend
6. **L'API dÃ©clenche la tÃ¢che d'indexation** (Celery)
7. **Le worker lit les rÃ©sultats et les indexe dans OpenSearch**
8. **L'utilisateur peut rechercher** dans les Ã©vÃ©nements via l'interface
9. **L'utilisateur peut crÃ©er des rÃ¨gles** de dÃ©tection
10. **L'utilisateur exporte une timeline** pour le rapport

---

## ğŸ“ Prochaines Ã©tapes

- [ ] CrÃ©er des composants React pour la recherche
- [ ] Ajouter un bouton "Indexer" dans PipelineView
- [ ] CrÃ©er une vue Explorer pour la recherche
- [ ] ImplÃ©menter le systÃ¨me de rÃ¨gles
- [ ] Ajouter l'export de timeline
- [ ] CrÃ©er des dashboards OpenSearch personnalisÃ©s

---

## ğŸ“š Documentation API

Tous les endpoints sont documentÃ©s dans Swagger UI:

**http://localhost:8000/docs**

Sections:
- **cases** - Gestion des investigations
- **evidence** - Gestion des preuves
- **pipeline** - Orchestration des parsers
- **indexing** - âœ¨ Nouveau: DÃ©clenchement de l'indexation
- **search** - âœ¨ Nouveau: Recherche dans OpenSearch

---

Vous avez maintenant une stack complÃ¨te fonctionnelle! ğŸ‰

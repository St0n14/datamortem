# Guide de d√©marrage de la stack compl√®te dataMortem

Ce guide explique comment d√©marrer toute la stack dataMortem avec OpenSearch int√©gr√©.

## üéØ Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    FRONTEND (React)                      ‚îÇ
‚îÇ                   http://localhost:5174                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ REST API
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    API FastAPI                           ‚îÇ
‚îÇ                   http://localhost:8080                  ‚îÇ
‚îî‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
  ‚îÇ             ‚îÇ             ‚îÇ             ‚îÇ
  ‚ñº             ‚ñº             ‚ñº             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇPostgreSQL‚îÇ ‚îÇRedis ‚îÇ   ‚îÇ OpenSearch  ‚îÇ ‚îÇ   Celery   ‚îÇ
‚îÇ  :5432  ‚îÇ ‚îÇ:6379 ‚îÇ   ‚îÇ    :9200    ‚îÇ ‚îÇ   Worker   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üìã Pr√©requis

- **Docker** et **Docker Compose**
- **Python 3.10+** avec **uv** install√©
- **Node.js 18+** et **npm**
- **PostgreSQL client** (psql) - optionnel pour debug

## üöÄ D√©marrage rapide (automatique)

### Option 1: Script tout-en-un

```bash
# Rendre le script ex√©cutable
chmod +x start-stack.sh

# D√©marrer toute la stack
./start-stack.sh
```

Ce script va automatiquement:
1. ‚úÖ D√©marrer PostgreSQL, Redis, OpenSearch (Docker)
2. ‚úÖ Cr√©er la base de donn√©es
3. ‚úÖ D√©marrer Celery Worker
4. ‚úÖ D√©marrer l'API FastAPI
5. ‚úÖ D√©marrer le Frontend React

**Arr√™ter la stack:**
```bash
./stop-stack.sh
```

---

### Mode multi-r√©plicas / load balancing (local)

Une instance Traefik est maintenant incluse pour √©quilibrer les requ√™tes entre plusieurs API FastAPI.

1. D√©marrer la stack compl√®te :
   ```bash
   docker-compose up -d --build
   ```
2. Ajouter des r√©plicas API (et workers) √† la vol√©e :
   ```bash
   docker-compose up -d --scale api=2 --scale celery-worker=2
   ```
3. V√©rifier que le load balancer r√©pond :
   ```bash
   curl http://localhost:8080/health
   ```

Traefik √©coute sur `http://localhost:8080` et route automatiquement vers tous les conteneurs `api`. Le frontend (port 5174) et les clients doivent maintenant appeler `http://localhost:8080/api/...`.

---

## üîß D√©marrage manuel (√©tape par √©tape)

### √âTAPE 1: D√©marrer les services Docker

```bash
# D√©marre PostgreSQL, Redis, OpenSearch, Dashboards
docker-compose up -d

# V√©rifier que tous les services sont UP
docker-compose ps
```

Attendez ~30 secondes que OpenSearch d√©marre.

**V√©rifications:**
```bash
# PostgreSQL
docker exec datamortem-postgres pg_isready -U datamortem

# Redis
docker exec datamortem-redis redis-cli ping

# OpenSearch
curl http://localhost:9200
```

---

### √âTAPE 2: Configuration de l'API

Le fichier `.env` est d√©j√† configur√© pour utiliser la stack Docker:

```bash
cat services/api/.env
```

Devrait contenir:
```env
DM_ENV=development
DM_DB_URL=postgresql://datamortem:datamortem_dev_password@localhost:5432/datamortem
DM_CELERY_BROKER=redis://localhost:6379/0
DM_CELERY_BACKEND=redis://localhost:6379/1
DM_OPENSEARCH_HOST=localhost
DM_OPENSEARCH_PORT=9200
...
```

> üîê **Important ‚Äì DM_JWT_SECRET obligatoire**
>
> - G√©n√©rez un secret al√©atoire d‚Äôau moins 32 caract√®res, par exemple :
>   ```bash
>   openssl rand -hex 32
>   ```
> - Ajoutez la valeur √† `services/api/.env` :
>   ```
>   DM_JWT_SECRET=6f8d4f0d4bb24e50a8d14bb6b1c8d9b2...
>   ```
> - L‚ÄôAPI refusera de d√©marrer si ce secret est absent ou trop court (pour √©viter les tokens falsifi√©s).

---

### √âTAPE 3: Installer les d√©pendances Python

```bash
cd services/api
uv sync
```

---

### √âTAPE 4: Cr√©er la base de donn√©es

```bash
cd services/api

# Cr√©er les tables via SQLAlchemy
uv run python -c "from app.db import Base, engine; Base.metadata.create_all(bind=engine)"

# OU via Alembic si configur√©
# uv run alembic upgrade head
```

**V√©rification:**
```bash
# Connexion √† PostgreSQL
docker exec -it datamortem-postgres psql -U datamortem -d datamortem

# Lister les tables
\dt

# Quitter
\q
```

---

### √âTAPE 5: D√©marrer Celery Worker

**Terminal 1 - Celery Worker:**
```bash
cd services/api
uv run celery -A app.celery_app worker --loglevel=info
```

Vous devriez voir:
```
-------------- celery@hostname v5.4.0
---- **** -----
...
[tasks]
  . app.tasks.index_results.bulk_index_case_results
  . app.tasks.index_results.index_results_task
  . app.tasks.parse_mft.parse_mft_task
```

---

### √âTAPE 6: D√©marrer l'API FastAPI

**Terminal 2 - API:**
```bash
cd services/api
uv run uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```

**V√©rification:**
```bash
# Health check
curl http://localhost:8080/health

# OpenSearch health
curl http://localhost:8080/api/search/health

# Swagger UI
open http://localhost:8080/docs
```

---

### √âTAPE 7: D√©marrer le Frontend

**Terminal 3 - Frontend:**
```bash
cd frontend

# Installer les d√©pendances (premi√®re fois)
npm install

# D√©marrer le dev server
npm run dev
```

Le frontend sera accessible sur **http://localhost:5174**

---

## üß™ Tester l'int√©gration compl√®te

### 1. Cr√©er un case de test

```bash
curl -X POST http://localhost:8080/api/cases \
  -H "Content-Type: application/json" \
  -d '{
    "case_id": "case_demo_001",
    "note": "Case de d√©monstration OpenSearch"
  }'
```

### 2. Cr√©er une evidence (fictive)

```bash
curl -X POST http://localhost:8080/api/evidence \
  -H "Content-Type: application/json" \
  -d '{
    "evidence_uid": "evidence_demo_001",
    "case_id": "case_demo_001",
    "local_path": "/tmp/dummy.raw"
  }'
```

### 3. Simuler un parsing (cr√©er des donn√©es de test)

```bash
cd services/api
python test_opensearch.py
```

### 4. D√©clencher l'indexation depuis l'API

Supposons que vous avez un TaskRun avec id=1:

```bash
curl -X POST http://localhost:8080/api/indexing/task-run \
  -H "Content-Type: application/json" \
  -d '{
    "task_run_id": 1
  }'
```

### 5. Rechercher dans OpenSearch

```bash
curl -X POST http://localhost:8080/api/search/query \
  -H "Content-Type: application/json" \
  -d '{
    "query": "*",
    "case_id": "test_case_001",
    "size": 10
  }' | jq
```

### 6. Voir le r√©sum√© d'indexation d'un case

```bash
curl http://localhost:8080/api/indexing/case/test_case_001/summary | jq
```

---

## üé® Frontend - D√©clencher l'indexation depuis l'UI

Les nouveaux endpoints disponibles pour le frontend:

### Endpoint: Indexer un TaskRun sp√©cifique

```typescript
// POST /api/indexing/task-run
const response = await fetch('http://localhost:8080/api/indexing/task-run', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({ task_run_id: 123 })
});

const result = await response.json();
// { status: "triggered", message: "...", celery_task_id: "..." }
```

### Endpoint: Indexer tout un case

```typescript
// POST /api/indexing/case
const response = await fetch('http://localhost:8080/api/indexing/case', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    case_id: "case_123",
    force_reindex: false
  })
});
```

### Endpoint: Voir le r√©sum√© d'indexation

```typescript
// GET /api/indexing/case/{case_id}/summary
const response = await fetch(
  'http://localhost:8080/api/indexing/case/case_123/summary'
);

const summary = await response.json();
/*
{
  case_id: "case_123",
  task_runs: {
    total: 10,
    success: 8,
    indexable: 8
  },
  opensearch: {
    document_count: 15420,
    index_name: "datamortem-case-case_123"
  }
}
*/
```

### Endpoint: Rechercher

```typescript
// POST /api/search/query
const response = await fetch('http://localhost:8080/api/search/query', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    query: "svchost.exe",
    case_id: "case_123",
    from: 0,
    size: 50
  })
});

const results = await response.json();
/*
{
  hits: [...],      // Documents trouv√©s
  total: 42,        // Total de r√©sultats
  took: 15          // Temps de recherche (ms)
}
*/
```

---

## üìä Interfaces disponibles

| Service | URL | Description |
|---------|-----|-------------|
| **Frontend** | http://localhost:5174 | Interface React |
| **API** | http://localhost:8080 | API FastAPI |
| **API Docs** | http://localhost:8080/docs | Swagger UI |
| **OpenSearch** | http://localhost:9200 | API OpenSearch |
| **OpenSearch Dashboards** | http://localhost:5601 | Interface de visualisation |
| **PostgreSQL** | localhost:5432 | Base de donn√©es |
| **Redis** | localhost:6379 | Broker Celery |

---

## üêõ Troubleshooting

### Probl√®me: "Connection refused" PostgreSQL

```bash
# V√©rifier que PostgreSQL est up
docker logs datamortem-postgres

# Red√©marrer
docker-compose restart postgres
```

### Probl√®me: Celery ne re√ßoit pas les t√¢ches

```bash
# V√©rifier Redis
docker exec datamortem-redis redis-cli ping

# V√©rifier la configuration
cd services/api
uv run python -c "from app.config import settings; print(settings.dm_celery_broker)"

# Devrait afficher: redis://localhost:6379/0
```

### Probl√®me: OpenSearch ne d√©marre pas

```bash
# V√©rifier les logs
docker logs datamortem-opensearch

# V√©rifier la m√©moire allou√©e
docker stats datamortem-opensearch

# Augmenter la m√©moire si besoin (modifier docker-compose.yml)
# OPENSEARCH_JAVA_OPTS=-Xms1g -Xmx1g
```

### Probl√®me: API ne se connecte pas √† OpenSearch

```bash
# Tester depuis l'API
cd services/api
uv run python -c "
from app.opensearch.client import get_opensearch_client, test_connection
from app.config import settings
client = get_opensearch_client(settings)
print(test_connection(client))
"
```

---

## üìù Logs

Les logs sont dans le r√©pertoire `logs/`:

```bash
# API
tail -f logs/api.log

# Celery Worker
tail -f logs/celery-worker.log

# Frontend
tail -f logs/frontend.log

# Docker services
docker-compose logs -f opensearch
docker-compose logs -f postgres
docker-compose logs -f redis
```

---

## üîÑ Workflow complet

1. **L'utilisateur cr√©e un case** via le frontend
2. **L'utilisateur upload une evidence** (image disque)
3. **L'utilisateur lance des parsers** (MFT, Prefetch, Registry...)
4. **Les parsers s'ex√©cutent via Celery** et produisent des r√©sultats (CSV/Parquet)
5. **L'utilisateur clique sur "Indexer"** dans le frontend
6. **L'API d√©clenche la t√¢che d'indexation** (Celery)
7. **Le worker lit les r√©sultats et les indexe dans OpenSearch**
8. **L'utilisateur peut rechercher** dans les √©v√©nements via l'interface
9. **L'utilisateur peut cr√©er des r√®gles** de d√©tection
10. **L'utilisateur exporte une timeline** pour le rapport

---

## üéì Prochaines √©tapes

- [ ] Cr√©er des composants React pour la recherche
- [ ] Ajouter un bouton "Indexer" dans PipelineView
- [ ] Cr√©er une vue Explorer pour la recherche
- [ ] Impl√©menter le syst√®me de r√®gles
- [ ] Ajouter l'export de timeline
- [ ] Cr√©er des dashboards OpenSearch personnalis√©s

---

## üìö Documentation API

Tous les endpoints sont document√©s dans Swagger UI:

**http://localhost:8080/docs**

Sections:
- **cases** - Gestion des investigations
- **evidence** - Gestion des preuves
- **pipeline** - Orchestration des parsers
- **indexing** - ‚ú® Nouveau: D√©clenchement de l'indexation
- **search** - ‚ú® Nouveau: Recherche dans OpenSearch

---

Vous avez maintenant une stack compl√®te fonctionnelle! üéâ

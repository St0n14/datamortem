# ‚úÖ Stack dataMortem - Statut Op√©rationnel

**Date:** 2025-11-06 12:05
**Status:** ‚úÖ STACK OPERABLE EN LOCAL (LB + marketplace, quotas)

---

## üÜï Changements r√©cents

- ‚úÖ **S√©curit√© API** : RBAC complet (ownership cases/√©vidences) + endpoints prot√©g√©s.
- ‚úÖ **Quotas utilisateurs** : un seul case pour les analystes, limite de 20‚ÄØGo sur les evidences (admins exempt√©s).
- ‚úÖ **Scripts personnalis√©s & marketplace** : stockage + ex√©cution Python pour admins, marketplace consultable par tous, assignation contr√¥l√©e via un admin.
- ‚úÖ **Durcissement scripts** : endpoints admin-only, noms sanitiz√©s, ex√©cution localis√©e pending sandbox.
- ‚úÖ **Load balancing local** : Traefik devant plusieurs r√©plicas FastAPI, frontend/config adapt√©s (`http://localhost:8080`).
- ‚úÖ **Tests de charge** : scripts k6 (`load-tests/`) pour valider la mont√©e en charge avant industrialisation.
- ‚úÖ Config centralis√©e via `.env`, Explorer moderne, timeline qui se r√©initialise correctement.

---

## üöÄ Services en cours d'ex√©cution

| Service | Status | Port | PID |
|---------|--------|------|-----|
| **PostgreSQL** | ‚úÖ Running | 5432 | Docker |
| **Redis** | ‚úÖ Running | 6379 | Docker |
| **OpenSearch** | ‚úÖ Running | 9200 | Docker |
| **OpenSearch Dashboards** | ‚úÖ Running | 5601 | Docker |
| **Traefik (LB)** | ‚úÖ Running | 8080 | Docker |
| **API FastAPI** | ‚úÖ Running | interne 8000 (via Traefik) | Voir api.pid |
| **Celery Worker** | ‚úÖ Running | - | Voir celery-worker.pid |

---

## üìä V√©rifications effectu√©es

- ‚úÖ PostgreSQL: Tables cr√©√©es avec succ√®s
- ‚úÖ Redis: Connexion OK
- ‚úÖ OpenSearch: Version 2.17.0, Cluster GREEN
- ‚úÖ API FastAPI: Health check OK
- ‚úÖ Celery Worker: 3 t√¢ches charg√©es
- ‚úÖ Int√©gration OpenSearch: Tests passent
- ‚úÖ Endpoints API: Fonctionnels

---

## üåê URLs disponibles

### Application
- **Frontend**: http://localhost:5174
- **API (via Traefik)**: http://localhost:8080
- **API Docs (Swagger)**: http://localhost:8080/docs

### Services
- **OpenSearch**: http://localhost:9200
- **OpenSearch Dashboards**: http://localhost:5601
- **PostgreSQL**: localhost:5432 (user: datamortem, db: datamortem)
- **Redis**: localhost:6379

---

## üéØ Endpoints API cl√©s

### Indexation (Nouveaux!)
```bash
# Indexer un TaskRun sp√©cifique
POST /api/indexing/task-run
Body: { "task_run_id": 123 }

# Indexer tout un case
POST /api/indexing/case
Body: { "case_id": "case_123", "force_reindex": false }

# R√©sum√© d'indexation d'un case
GET /api/indexing/case/{case_id}/summary

# Status d'une t√¢che
GET /api/indexing/status/{task_run_id}
```

### Recherche OpenSearch (Nouveaux!)
```bash
# Recherche simple
POST /api/search/query
Body: { "query": "svchost.exe", "case_id": "case_123", "size": 50 }

# Agr√©gations
POST /api/search/aggregate
Body: { "case_id": "case_123", "field": "event.type", "size": 10 }

# Timeline
POST /api/search/timeline
Body: { "case_id": "case_123", "interval": "1h" }

# Statistiques d'index
GET /api/search/stats/{case_id}

# Sant√© OpenSearch
GET /api/search/health
```

### Cases, Evidence, Pipeline (Existants + CRUD)
- POST /api/cases - Cr√©er un case
- GET /api/cases - Lister les cases
- GET /api/cases/{case_id} - D√©tail d‚Äôun case
- PATCH /api/cases/{case_id} - Mettre √† jour note ou status
- DELETE /api/cases/{case_id} - Supprimer un case (cascade sur evidences/task runs)
- POST /api/evidence - Ajouter une evidence
- POST /api/pipeline/run - Lancer un parser

---

## üß™ Tester l'int√©gration

### 1. Cr√©er un case
```bash
curl -X POST http://localhost:8080/api/cases \
  -H "Content-Type: application/json" \
  -d '{"case_id": "test_001", "note": "Test case"}'
```

### 2. V√©rifier la sant√© OpenSearch
```bash
curl http://localhost:8080/api/search/health | jq
```

### 3. Voir le r√©sum√© d'indexation
```bash
curl http://localhost:8080/api/indexing/case/test_001/summary | jq
```

---

## üìù Logs

Les logs sont disponibles dans le r√©pertoire `logs/`:

```bash
# API
tail -f logs/api.log

# Celery Worker
tail -f logs/celery-worker.log

# Services Docker
docker-compose logs -f opensearch
docker-compose logs -f postgres
docker-compose logs -f redis
```

---

## üõë Arr√™ter la stack

### Arr√™t complet (script)
```bash
./stop-stack.sh
```

### Arr√™t manuel
```bash
# Arr√™ter API et Celery
kill $(cat api.pid)
kill $(cat celery-worker.pid)

# Arr√™ter Docker
docker-compose down
```

---

## üé® Int√©gration Frontend

Pour d√©clencher l'indexation depuis React:

```typescript
// Exemple: Bouton "Indexer" dans PipelineView
const handleIndex = async (taskRunId: number) => {
  const response = await fetch('http://localhost:8080/api/indexing/task-run', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ task_run_id: taskRunId })
  });

  const result = await response.json();

  if (result.status === 'triggered') {
    alert(`Indexation d√©marr√©e! Celery Task: ${result.celery_task_id}`);
  }
};

// Exemple: Recherche
const handleSearch = async (caseId: string, query: string) => {
  const response = await fetch('http://localhost:8080/api/search/query', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      query,
      case_id: caseId,
      size: 50
    })
  });

  const results = await response.json();
  setSearchResults(results.hits);
};
```

---

## üîß Configuration

### Fichiers de configuration
- **API**: `services/api/.env`
- **Docker**: `docker-compose.yml`

### Variables d'environnement importantes
```env
DM_ENV=development
DM_DB_URL=postgresql://datamortem:datamortem_dev_password@localhost:5432/datamortem
DM_CELERY_BROKER=redis://localhost:6379/0
DM_CELERY_BACKEND=redis://localhost:6379/1
DM_OPENSEARCH_HOST=localhost
DM_OPENSEARCH_PORT=9200
```

---

## üìö Documentation

- **Guide rapide**: `QUICK_START.md`
- **Guide complet**: `STACK_SETUP.md`
- **Tests OpenSearch**: `services/api/OPENSEARCH_TESTING.md`
- **API Interactive**: http://localhost:8080/docs

---

## ‚úÖ Prochaines √©tapes

1. **Frontend**: Ajouter des boutons "Indexer" dans PipelineView
2. **Frontend**: Cr√©er une vue "Explorer" pour la recherche
3. **Frontend**: Afficher les statistiques d'indexation
4. **Backend**: Cha√Ænage automatique parsing ‚Üí indexation
5. **Backend**: Syst√®me de r√®gles de d√©tection
6. **Frontend**: Pagination/virtualisation timeline quand on activera la pagination OpenSearch

---

**La stack est pr√™te √† √™tre utilis√©e!** üéâ

Pour toute question, consultez la documentation ou les logs.

## üìà Tests de mont√©e en charge

- Scripts k6 dans `load-tests/` (`health-smoke.js`, `search-health-throughput.js`)
- Exemple : `k6 run load-tests/health-smoke.js` (configurable via `API_BASE_URL`, `VUS`, etc.)
- Sert √† valider Traefik + scaling (`docker-compose up -d --scale api=2`)

---

## ‚úÖ Travail r√©alis√©

1. **S√©curisation backend**
   - Auth JWT + RBAC par case/√©vidence/pipeline/indexing
   - Routes publiques verrouill√©es, artefacts confin√©s √† `/lake`
2. **Scripts custom & pipeline**
   - CRUD des scripts (Python/Perl/Rust), ex√©cution Celery + stockage output
   - UI Scripts pour cr√©ation, copie, ex√©cution cibl√©e
3. **Load balancing local**
   - Traefik ajout√© √† docker-compose, front/config pointent vers `:8080`
   - Docs/scripts mis √† jour (`start-stack.sh`, `STACK_SETUP.md`)
4. **Outils de test**
   - Scripts k6 + documentation pour mont√©e en charge locale
   - Guide pour scaler API/workers avec `docker-compose`

---

- **New Case button** : au besoin, le 1·µâ ≥ case peut d√©sormais √™tre cr√©√© via l‚ÄôUI (bouton ‚ÄúCreate first case‚Äù), sinon un admin doit le faire.
- **‚ö†Ô∏è Migrations DB** : appliquer les colonnes `task_run.script_id`, `custom_scripts.is_approved`, `user_scripts` avant production (cf. instructions DB).

---

## üîú Reste √† faire

- [ ] Externaliser `/lake` (S3/GCS ou volume partag√©) pour pr√©parer le multi-n≈ìuds.
- [ ] Passer Postgres/Redis/OpenSearch en services manag√©s ou multi-n≈ìuds.
- [ ] D√©finir l‚Äôorchestrateur cible (GKE/Cloud Run/Swarm) + ingress prod.
- [ ] Ajouter du monitoring (Prometheus/Grafana ou Cloud Monitoring) + alertes.
- [ ] Finaliser la mont√©e en charge (CI/CD, Terraform/Helm) une fois les choix infra valid√©s.
- [ ] ‚ö†Ô∏è Sandbox scripts custom avant d√©ploiement GCP (conteneur d√©di√©, montages read-only). Bloquer la fonctionnalit√© si sandbox absent.

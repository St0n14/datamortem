# Requiem - Architecture Overview

## ğŸ¯ Vision du Projet

Requiem est une plateforme d'analyse forensique d'hÃ´te combinant :
- La puissance d'exploration d'**OpenSearch**
- La capacitÃ© de rÃ¨gles et timeline de **Timesketch**
- L'orchestration DFIR avec support multi-langages

---

## ğŸ“ Architecture Globale

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        FRONTEND LAYER                            â”‚
â”‚                     (React + Vite)                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Case Manager â”‚  Parser UI   â”‚  Explorer    â”‚  Timeline    â”‚ â”‚
â”‚  â”‚              â”‚              â”‚  (Search)    â”‚  (Rules)     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ REST API / WebSocket
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       API LAYER                                  â”‚
â”‚                 (Django + FastAPI)                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  API Endpoints:                                           â”‚  â”‚
â”‚  â”‚  â€¢ Case Management    â€¢ Parser Registry                  â”‚  â”‚
â”‚  â”‚  â€¢ Task Orchestration â€¢ Search Proxy (OpenSearch)        â”‚  â”‚
â”‚  â”‚  â€¢ Results Retrieval  â€¢ Timeline & Rules Engine          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚               â”‚               â”‚
         â–¼               â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   REDIS     â”‚  â”‚  PostgreSQL â”‚  â”‚ OpenSearch  â”‚
â”‚  (Broker)   â”‚  â”‚   (Meta)    â”‚  â”‚  (Search)   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”˜
       â”‚                                   â”‚
       â”‚ Tasks Queue                       â”‚ Indexation
       â–¼                                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
â”‚              WORKER LAYER (Celery)              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚         Task Orchestrator                â”‚  â”‚
â”‚  â”‚  â€¢ Gestion du cycle de vie des parsers   â”‚  â”‚
â”‚  â”‚  â€¢ Build Ã  la volÃ©e (Go/Rust)            â”‚  â”‚
â”‚  â”‚  â€¢ Monitoring & retry logic              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                 â”‚                                â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚     â–¼           â–¼           â–¼                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚Pythonâ”‚   â”‚ Go  â”‚   â”‚  Rust   â”‚              â”‚
â”‚  â”‚Parserâ”‚   â”‚Parser   â”‚ Parser  â”‚              â”‚
â”‚  â””â”€â”€â”€â”¬â”€â”€â”˜   â””â”€â”€â”¬â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜              â”‚
â””â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚         â”‚           â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚ Parquet/JSON
              â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚   STORAGE   â”‚
       â”‚  (S3/Local) â”‚
       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â”‚ Ingestion Pipeline
              â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚ OpenSearch  â”‚
       â”‚  Indexing   â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ Composants ClÃ©s

### 1. **Frontend Layer (React + Vite)**

**RÃ´le :** Interface utilisateur pour les analystes forensiques

**Modules :**
- **Case Manager** : CrÃ©ation et gestion des investigations
- **Parser UI** : SÃ©lection, configuration et lancement des parsers
- **Explorer** : Interface de recherche OpenSearch (type Kibana simplifiÃ©)
- **Timeline** : Visualisation temporelle avec systÃ¨me de rÃ¨gles

### 2. **API Layer (FastAPI)**

**RÃ´le :** Orchestration et exposition des services

**ResponsabilitÃ©s :**
- Authentification JWT avec support OTP/2FA (TOTP)
- RBAC (superadmin, admin, analyst, viewer) avec permissions granulaires
- Gestion des cases (investigations) avec ownership
- Registry des parsers disponibles (AnalysisModule)
- Marketplace de scripts custom Python avec installation/exÃ©cution isolÃ©e
- DÃ©clenchement des tÃ¢ches Celery
- Proxy vers OpenSearch avec recherche, agrÃ©gations, timeline
- Gestion des utilisateurs avec email verification optionnelle
- Quotas utilisateurs (analysts: 1 case, 20GB evidences)

**Technologies :**
- FastAPI : Framework REST moderne avec validation Pydantic
- SQLAlchemy 2.x : ORM avec PostgreSQL
- bcrypt : Password hashing sÃ©curisÃ©
- PyJWT : Tokens JWT avec expiration 24h
- pyotp : TOTP pour authentification 2FA
- opensearch-py : Client OpenSearch officiel

### 3. **Message Broker (Redis)**

**RÃ´le :** Queue de tÃ¢ches pour Celery

**Usage :**
- Distribution des jobs de parsing
- Gestion de la prioritÃ© des tÃ¢ches
- Cache pour les rÃ©sultats intermÃ©diaires

### 4. **Metadata Store (PostgreSQL)**

**RÃ´le :** Stockage des mÃ©tadonnÃ©es

**Contenu :**
- **Users** : Comptes utilisateurs avec hashed passwords, OTP secrets, email verification tokens
- **Cases** : Investigations avec ownership, status, notes markdown, liens HedgeDoc
- **Evidences** : Artefacts forensiques avec chemins stockage, mÃ©tadonnÃ©es
- **AnalysisModule** : Registry des parsers (nom, description, tool, enabled)
- **TaskRun** : Historique d'exÃ©cutions (status, timestamps, output paths, error messages)
- **CustomScript** : Scripts marketplace (Python code, requirements, approval status)
- **UserScript** : Table de liaison installations utilisateurs
- **Events** : Ã‰vÃ©nements bruts avant indexation OpenSearch (optionnel)

**ModÃ¨le User :**
- Champs auth : email, username, hashed_password
- RBAC : role (superadmin/admin/analyst/viewer), is_active, is_superuser
- OTP/2FA : otp_enabled, otp_secret
- Email verification : email_verified, email_verification_token, email_verification_sent_at
- Audit : created_at_utc, last_login_utc

### 5. **Worker Layer (Celery)**

**RÃ´le :** ExÃ©cution distribuÃ©e des parsers et scripts

**FonctionnalitÃ©s :**
- **Parsers natifs** : ExÃ©cution de modules d'analyse (MFT, EVTx, Registry...)
- **Scripts custom** : Isolation complÃ¨te dans virtualenv dÃ©diÃ© par script
- **Monitoring** : Progression, logs, erreurs dans TaskRun
- **Resilience** : Retry automatique (max_retries=3), timeout
- **Stockage organisÃ©** : `/lake/{case_id}/{evidence_uid}/{parser_name}/`

**Types de tÃ¢ches actuellement implÃ©mentÃ©es :**
- `parse_mft_task` : Parser Master File Table Windows
- `sample_long_task` : Test de tÃ¢che longue durÃ©e
- `generate_test_events` : GÃ©nÃ©ration d'Ã©vÃ©nements de test
- `parse_with_dissect` : Parser gÃ©nÃ©rique Dissect
- `dissect_extract_mft` : MFT via Dissect Target
- `run_custom_script` : ExÃ©cution de scripts marketplace dans venv isolÃ©
- `index_results_task` : Indexation Parquet/CSV/JSONL vers OpenSearch

**Isolation scripts custom :**
- RÃ©pertoire dÃ©diÃ© : `/lake/{case_id}/{evidence_uid}/scripts/{script_name}_{id}/`
- Virtualenv Python dÃ©diÃ© : `python -m venv venv/`
- Installation dÃ©pendances isolÃ©e : `pip install -r requirements.txt`
- Variables d'environnement injectÃ©es : `CASE_ID`, `EVIDENCE_UID`, `EVIDENCE_PATH`, `OUTPUT_DIR`
- Capture stdout/stderr dans `output.txt`

### 6. **Parsers (Multi-langages)**

**RÃ´le :** Extraction et normalisation des artefacts

**CaractÃ©ristiques :**
- **Standalone** : Chaque parser est autonome
- **Multi-formats** : Input variÃ© (logs, registry, mÃ©moire...)
- **Output standardisÃ©** : Parquet (stockage) + JSON (indexation)

**Structure output :**
```json
{
  "@timestamp": "2024-11-05T10:30:00Z",
  "source.parser": "prefetch_parser",
  "event.type": "process",
  "host.id": "case_123_host_01",
  "case.id": "case_123",
  // Champs spÃ©cifiques au parser...
}
```

### 7. **Storage Layer**

**RÃ´le :** Persistance des rÃ©sultats bruts et artefacts forensiques

**Configuration actuelle :**
- Stockage local : `/lake` (volume Docker `lake-data`)
- TODO : Support S3/GCS pour multi-nÅ“uds (prod)

**Organisation hiÃ©rarchique :**
```
/lake
  /{case_id}
    /{evidence_uid}
      /raw/                           # Artefacts originaux uploadÃ©s
        - disk.E01
        - memory.dump
      /mft/                           # RÃ©sultats parser MFT
        - results.parquet
        - output.txt
      /evtx/                          # RÃ©sultats parser EVTx
        - results.parquet
      /scripts/                       # Scripts custom
        /{script_name}_{id}/
          - script.py
          - requirements.txt
          - venv/
          - output.txt
```

**Formats supportÃ©s :**
- **Input** : E01, raw, VMDK, memory dumps, logs, registry hives
- **Output parsers** : Parquet (prÃ©fÃ©rÃ©), CSV, JSONL
- **Scripts custom** : Format libre dans OUTPUT_DIR

### 8. **OpenSearch Cluster**

**RÃ´le :** Indexation et recherche des Ã©vÃ©nements forensiques

**Configuration :**
- **Version** : OpenSearch 2.17.0
- **Index pattern** : `requiem-case-{case_id}` (un index par case)
- **Mapping hybride** : Champs communs stricts + dynamic templates pour champs spÃ©cifiques
- **Retention** : Par case (suppression quand case clÃ´turÃ© ou via API)
- **Sharding** : 1 shard (dev), 3+ shards (prod)
- **Replicas** : 0 (dev), 1+ (prod)
- **Bulk indexing** : 500 documents par batch

**Champs communs (ECS-inspired) :**
```json
{
  "@timestamp": "date",           // Requis, normalisÃ© ISO8601
  "case": {
    "id": "keyword",
    "name": "keyword"
  },
  "evidence": {
    "uid": "keyword"
  },
  "source": {
    "parser": "keyword"           // Ex: "parse_mft", "custom_script_X"
  },
  "event": {
    "type": "keyword",            // Ex: "process", "network", "file"
    "category": "keyword"
  },
  "host": {
    "id": "keyword",
    "hostname": "keyword"
  },
  "user": {
    "name": "keyword"
  },
  "message": "text",              // Full-text search
  "tags": "keyword[]",
  "score": "integer",             // PrioritÃ©/severity
  "indexed_at": "date",           // Metadata indexation
  "raw": "text"                   // DonnÃ©es brutes optionnelles
}
```

**API Endpoints OpenSearch :**
- `POST /api/search/query` : Recherche full-text avec filtres
- `POST /api/search/aggregate` : AgrÃ©gations (terms, date_histogram...)
- `POST /api/search/timeline` : Timeline d'Ã©vÃ©nements avec intervalle
- `GET /api/search/stats/{case_id}` : Statistiques index (doc count, size, parsers)
- `GET /api/search/health` : SantÃ© cluster OpenSearch

**Features :**
- Full-text search sur champ `message`
- Filtres multiples (event.type, tags, host.id...)
- AgrÃ©gations pour analytics (top hosts, event types, timeline)
- Pagination (from/size)
- Sort personnalisÃ©

### 9. **SystÃ¨me d'authentification & RBAC**

**Authentification JWT :**
- Tokens JWT signÃ©s avec HS256 (secret min 32 chars)
- Expiration : 24 heures
- Payload : user ID, username, email, role
- Header `Authorization: Bearer {token}` pour tous les endpoints protÃ©gÃ©s

**OTP/2FA (TOTP) :**
- Activation optionnelle par utilisateur (DM_ENABLE_OTP=true)
- Secret gÃ©nÃ©rÃ© avec `pyotp.random_base32()`
- QR code affichÃ© dans l'UI pour scan (Google Authenticator, Microsoft Authenticator, 1Password...)
- Code requis au login si OTP activÃ©
- FenÃªtre de validation : Â±30 secondes (standard TOTP)
- DÃ©sactivation nÃ©cessite un code valide

**Email Verification (optionnelle) :**
- Configuration : DM_ENABLE_EMAIL_VERIFICATION=true
- Token unique gÃ©nÃ©rÃ© Ã  l'inscription (`secrets.token_urlsafe(32)`)
- Email envoyÃ© avec lien de vÃ©rification
- Login bloquÃ© jusqu'Ã  vÃ©rification si activÃ©
- Renvoi de lien disponible

**RBAC - 4 rÃ´les hiÃ©rarchiques :**

1. **superadmin** (`is_superuser=True`)
   - Gestion complÃ¨te du systÃ¨me
   - CRUD utilisateurs avec assignation de rÃ´les
   - Gestion marketplace : crÃ©ation, approbation, assignation scripts
   - Import scripts depuis GitHub
   - AccÃ¨s total Ã  tous les cases
   - Pas de quotas

2. **admin**
   - AccÃ¨s lecture/Ã©criture Ã  tous les cases
   - ExÃ©cution de tous les parsers et scripts
   - Voir statistiques systÃ¨me
   - Pas de gestion utilisateurs ni marketplace
   - Pas de quotas

3. **analyst** (rÃ´le par dÃ©faut)
   - CrÃ©e et gÃ¨re uniquement ses propres cases
   - Upload evidences et exÃ©cution parsers
   - Installation scripts depuis marketplace
   - **Quotas** : 1 case actif max, 20GB evidences max
   - Pas d'accÃ¨s aux cases d'autres utilisateurs

4. **viewer** (lecture seule)
   - Lecture sur cases assignÃ©s uniquement
   - Pas de crÃ©ation/modification
   - Pas d'exÃ©cution de parsers/scripts

**Permissions vÃ©rifiÃ©es sur chaque endpoint :**
- Ownership check : `case.owner_id == user.id` (sauf admins)
- Role check : `user.role in ["admin", "superadmin"]`
- Dependencies FastAPI : `get_current_active_user`, `get_current_admin_user`, `get_current_superadmin_user`

### 10. **Marketplace de scripts**

**Architecture :**
- Scripts Python stockÃ©s dans PostgreSQL (`CustomScript`)
- Installation par utilisateur (`UserScript` table de liaison)
- ExÃ©cution isolÃ©e dans virtualenv dÃ©diÃ©

**Workflow marketplace :**

1. **CrÃ©ation (superadmin uniquement) :**
   - `POST /api/scripts` avec code source complet
   - Champs : name, description, language, python_version, requirements, source_code
   - Status initial : `is_approved=False`

2. **Approbation (superadmin) :**
   - `POST /api/scripts/{id}/approve?approved=true`
   - Review manuel du code avant approbation
   - Date de publication enregistrÃ©e

3. **Marketplace (tous utilisateurs) :**
   - `GET /api/scripts/marketplace` : Liste scripts approuvÃ©s uniquement
   - Retourne rÃ©sumÃ© sans code source (sÃ©curitÃ©)

4. **Installation (tous utilisateurs) :**
   - `POST /api/scripts/{id}/install` : Ajoute script aux "mes scripts"
   - CrÃ©Ã© entrÃ©e dans `UserScript` avec timestamp

5. **ExÃ©cution (admin/analyst owner) :**
   - `POST /api/scripts/{id}/run` avec `evidence_uid`
   - TÃ¢che Celery `run_custom_script` :
     - CrÃ©e rÃ©pertoire isolÃ©
     - Ã‰crit code dans `script.py`
     - CrÃ©Ã© virtualenv : `python -m venv venv/`
     - Installe dÃ©pendances : `pip install -r requirements.txt`
     - Injecte variables d'environnement : CASE_ID, EVIDENCE_UID, EVIDENCE_PATH, OUTPUT_DIR
     - ExÃ©cute : `venv/bin/python script.py`
     - Capture stdout/stderr

6. **Import GitHub (superadmin) :**
   - `POST /api/scripts/import-github` avec repo_url, branch, scripts_path
   - Parse tous les `.py` dans le rÃ©pertoire
   - CrÃ©Ã© scripts non-approuvÃ©s (review manuelle ensuite)
   - Retourne statistiques : imported, skipped, errors

**SÃ©curitÃ© scripts :**
- Isolation : virtualenv dÃ©diÃ© par exÃ©cution
- Sandboxing : limitÃ© Ã  `/lake` (TODO : conteneur dÃ©diÃ©)
- Approval workflow : superadmin valide avant publication
- Audit trail : TaskRun enregistre toutes les exÃ©cutions
- Variables d'environnement contrÃ´lÃ©es

### 11. **HedgeDoc Integration**

**RÃ´le :** Prise de notes collaboratives par case

**Workflow :**
- CrÃ©ation automatique d'un pad HedgeDoc Ã  la crÃ©ation du case
- Slug alÃ©atoire (32 chars) stockÃ© dans `Case.hedgedoc_slug`
- URL publique : `{DM_HEDGEDOC_PUBLIC_URL}/{slug}`
- Ã‰dition collaborative en temps rÃ©el (Markdown)
- Bouton "Ouvrir dans HedgeDoc" dans l'UI

**Configuration :**
- DM_HEDGEDOC_ENABLED=true
- DM_HEDGEDOC_BASE_URL=http://hedgedoc:3000 (interne)
- DM_HEDGEDOC_PUBLIC_URL=http://localhost:3000 (user)
- Service HedgeDoc + PostgreSQL dÃ©diÃ© (port 5433)

### 12. **Infrastructure & Load Balancing**

**Docker Compose Stack :**
- **Traefik** (port 8080) : Load balancer avec routing automatique
- **PostgreSQL** (port 5432) : MÃ©tadonnÃ©es
- **Redis** (port 6379) : Celery broker
- **OpenSearch** (port 9200) : Index
- **OpenSearch Dashboards** (port 5601) : Visualisation
- **API FastAPI** (port interne 8000, exposÃ© via Traefik)
- **Celery Worker** : Scaling horizontal prÃªt
- **Frontend React** (port 5174)
- **HedgeDoc** (port 3000) + HedgeDoc DB (port 5433)

**Scaling :**
```bash
docker-compose up -d --scale api=3      # 3 rÃ©plicas API
docker-compose up -d --scale worker=5   # 5 workers Celery
```
Traefik distribue automatiquement les requÃªtes.

**Volumes persistants :**
- postgres-data, redis-data, opensearch-data
- lake-data (artefacts forensiques)
- hedgedoc-db-data, hedgedoc-uploads

**Commandes Makefile :**
- `make demo` : Clean + start + ingestion donnÃ©es test
- `make up/down` : DÃ©marrer/arrÃªter stack
- `make logs SERVICE=api` : Voir logs
- `make clean` : Nettoyer volumes (DANGER : supprime donnÃ©es)
- `make shell-api` : Shell dans container API
- `make check-opensearch` : VÃ©rifier santÃ© OpenSearch

---

## ğŸ”„ Workflow Type

### ScÃ©nario : Analyse d'un disque Windows

1. **Analyste crÃ©e un case** via UI
   - Frontend â†’ API â†’ PostgreSQL
   - Case ID gÃ©nÃ©rÃ© : `case_123`

2. **Upload de l'image/artefacts**
   - Storage : `/storage/case_123/host_01/raw/`

3. **SÃ©lection des parsers** (ex: Prefetch, EVTx, Registry, MFT)
   - UI affiche parsers disponibles depuis registry
   - Analyste sÃ©lectionne + configure

4. **Lancement orchestrÃ©**
   - API â†’ Celery tasks crÃ©Ã©es pour chaque parser
   - Redis queue : `[prefetch_task, evtx_task, registry_task, mft_task]`

5. **Workers exÃ©cutent**
   - Worker 1 : Build Go parser â†’ Execute â†’ Output Parquet
   - Worker 2 : Python parser â†’ Execute â†’ Output Parquet
   - ParallÃ©lisation automatique

6. **Ingestion OpenSearch**
   - TÃ¢che Celery : `index_results`
   - Lecture Parquet â†’ Conversion JSON â†’ Bulk API OpenSearch
   - Mapping hybride appliquÃ©

7. **Exploration & Timeline**
   - Analyste recherche dans OpenSearch via UI
   - Application de rÃ¨gles de dÃ©tection
   - Annotation d'Ã©vÃ©nements suspects
   - Export de timeline

---

## ğŸ¨ Design Patterns

### Pattern 1 : **Registry de Parsers**

Les parsers sont dÃ©clarÃ©s dans PostgreSQL avec :
- MÃ©tadata (nom, langage, version)
- Configuration schema (JSON Schema)
- Build instructions (pour Go/Rust)
- Output schema (champs spÃ©cifiques)

Avantages :
- Ajout de parsers sans redÃ©ploiement
- Versionning
- UI dynamique

### Pattern 2 : **Pipeline d'Ingestion**

```
Parquet (storage) â†’ Celery Task â†’ Stream Processing â†’ Batch Bulk â†’ OpenSearch
```

- Traitement par chunks (Ã©vite OOM)
- Transformation : ajout des champs communs
- Validation du schema
- Bulk indexing pour performance

### Pattern 3 : **Task Chaining**

```python
# Exemple de chaÃ®ne de tÃ¢ches
chain(
    build_parser.si(parser_id="prefetch", lang="go"),
    parse_artifact.si(artifact_path="/storage/case_123/..."),
    index_results.si()
).apply_async()
```

Permet des workflows complexes (parser A â†’ parser B basÃ© sur rÃ©sultats A)

---

## ğŸ“Š Ã‰volutivitÃ©

### Phase 1 : Local/Dev (actuel)
- Tout sur une machine
- Docker Compose
- Volumes locaux

### Phase 2 : Small Team
- Workers sur plusieurs machines
- MinIO pour storage distribuÃ©
- OpenSearch 3 nodes

### Phase 3 : Enterprise
- Kubernetes
- S3 / Object Storage
- OpenSearch cluster dÃ©diÃ©
- Multi-tenancy (isolation par case)

---

## ğŸ” ConsidÃ©rations SÃ©curitÃ©

- **Isolation parsers** : Chaque parser dans un environnement contrÃ´lÃ©
- **Validation inputs** : Schema validation avant parsing
- **Audit trail** : Toutes actions loggÃ©es dans PostgreSQL
- **Access control** : Permissions par case (Django)
- **Data retention** : Politique de suppression automatique

---

## ğŸš€ Ã‰tat Actuel & Prochaines Ã‰tapes

### âœ… FonctionnalitÃ©s ImplÃ©mentÃ©es (Phase 1 complÃ¨te)

**Authentification & SÃ©curitÃ© :**
- âœ… JWT authentication avec expiration 24h
- âœ… OTP/2FA (TOTP) complet avec QR codes
- âœ… Email verification optionnelle
- âœ… RBAC 4 rÃ´les (superadmin, admin, analyst, viewer)
- âœ… Password hashing bcrypt
- âœ… User management (CRUD, change password, profile)

**Gestion de cas :**
- âœ… CRUD cases avec ownership
- âœ… Evidences upload et stockage `/lake`
- âœ… Notes markdown + HedgeDoc integration
- âœ… Quotas analysts (1 case, 20GB)
- âœ… Cascade delete

**Pipeline d'analyse :**
- âœ… Registry parsers (AnalysisModule)
- âœ… 5+ parsers (MFT, Dissect, test events)
- âœ… ExÃ©cution Celery avec monitoring
- âœ… TaskRun historique complet

**Marketplace scripts :**
- âœ… CRUD scripts (superadmin)
- âœ… Workflow approval
- âœ… Installation utilisateurs
- âœ… ExÃ©cution isolÃ©e (Docker sandbox)
- âœ… Import GitHub
- âœ… Support multi-langages (Python, Rust, Go)
- âœ… Limitations ressources (CPU, RAM, timeout)
- âœ… SÃ©curitÃ© renforcÃ©e (no network, read-only fs)

**OpenSearch :**
- âœ… Indexation Parquet/CSV/JSONL
- âœ… Index par case
- âœ… Bulk indexing (500 docs/batch)
- âœ… API recherche, agrÃ©gations, timeline
- âœ… Stats par case

**Interface :**
- âœ… Login/register avec OTP
- âœ… Case management
- âœ… Evidence management
- âœ… Pipeline view
- âœ… Explorer (search)
- âœ… Timeline
- âœ… Marketplace
- âœ… Admin panel
- âœ… Security settings
- âœ… Dark mode

**Infrastructure :**
- âœ… Docker Compose stack complÃ¨te
- âœ… Traefik load balancing
- âœ… Volumes persistants
- âœ… Makefile DX (+ commandes migrations)
- âœ… Scripts dÃ©mo/test
- âœ… Alembic migrations configurÃ©es

### ğŸ“‹ Production Readiness : ~60-65%

**Par catÃ©gorie :**
- SÃ©curitÃ© : 70% (+20% avec sandbox Docker)
- Auth/AuthZ : 80%
- API Protection : 60%
- Infrastructure : 50% (+20% avec Docker sandbox)
- Database Management : 80% (Alembic migrations)
- Script Execution : 85% (Sandbox multi-langages)
- Monitoring : 0%
- Testing : 10% (smoke tests sandbox)
- CI/CD : 0%

### ğŸ¯ Prochaines Ã‰tapes Prioritaires

**Court terme (1-2 semaines) :**
1. âœ… **Migrations Alembic** : Gestion schÃ©ma DB versionnÃ©e (COMPLÃ‰TÃ‰)
2. âœ… **Sandbox scripts** : Conteneur Docker dÃ©diÃ© pour exÃ©cution scripts custom (COMPLÃ‰TÃ‰)
3. **Storage S3/GCS** : Support object storage pour `/lake` (multi-nÅ“uds)
4. **Tests unitaires** : Couverture endpoints critiques (auth, RBAC, cases)
5. **Refresh tokens** : Renouvellement sans re-login
6. **Rate limiting** : Protection endpoints publics (login, register)

**Moyen terme (1-2 mois) :**
1. **CI/CD complet** : GitHub Actions (tests, build, deploy)
2. **Monitoring** : Prometheus + Grafana (mÃ©triques API, Celery, OpenSearch)
3. **Alertes** : Erreurs critiques, quotas dÃ©passÃ©s, health checks
4. **Postgres/Redis/OpenSearch managÃ©s** : Cloud SQL, Memorystore, Elastic Cloud
5. **Password reset** : Workflow via email
6. **Tests d'intÃ©gration** : Workflows end-to-end
7. **Parsers additionnels** : EVTx, Registry, Prefetch, PE modules

**Long terme (3-6 mois) :**
1. **Kubernetes deployment** : GKE/EKS avec Helm charts
2. **OAuth2/SSO** : Google, GitHub, SAML enterprise
3. **Recovery codes MFA** : Backup si perte device OTP
4. **API keys** : Authentification pour CI/CD et intÃ©grations
5. **Multi-tenancy** : Isolation complÃ¨te entre organisations
6. **Audit logs** : TraÃ§abilitÃ© complÃ¨te actions utilisateurs
7. **Terraform IaC** : Infrastructure as Code pour dÃ©ploiement cloud
8. **Advanced analytics** : ML pour dÃ©tection anomalies, clustering Ã©vÃ©nements

---

## ğŸ“ Notes Techniques

### Pourquoi Parquet ?
- Compression excellente (ratio 10:1 typique)
- Schema evolution
- Columnar = queries analytiques rapides
- Standard dans l'Ã©cosystÃ¨me data

### Pourquoi OpenSearch ?
- Full-text search puissant
- Aggregations pour analytics
- OpenSource vs Elasticsearch
- Dashboards inclus (alternative Kibana)

### Pourquoi Celery ?
- Mature et battle-tested
- Support multi-langages via subprocess
- Monitoring (Flower)
- Scaling horizontal facile

---

## ğŸ“š Documentation ComplÃ©mentaire

- **AUTHENTICATION.md** : Guide complet authentification (JWT, OTP, email verification, RBAC)
- **MIGRATIONS.md** : Guide des migrations Alembic (crÃ©ation, application, rollback)
- **SANDBOX.md** : Guide du sandbox multi-langages (Python, Rust, Go, sÃ©curitÃ©, exemples)
- **SANDBOX_SETUP.md** : RÃ©sumÃ© implÃ©mentation sandbox (fichiers crÃ©Ã©s, tests, roadmap)
- **QUICK_START.md** : DÃ©marrage rapide en 3 commandes
- **STACK_SETUP.md** : Configuration dÃ©taillÃ©e de la stack
- **STATUS.md** : Ã‰tat actuel du projet et changements rÃ©cents
- **PHASE1_COMPLETE.md** : DÃ©tails implÃ©mentation Phase 1 (Auth & SÃ©curitÃ©)
- **MAKEFILE.md** : Documentation des commandes Makefile
- **API Docs** : http://localhost:8080/docs (Swagger) et /redoc (ReDoc)

---

**Version:** 2.0
**Date:** 2025-11-11
**DerniÃ¨re mise Ã  jour:** Post-implÃ©mentation OTP/2FA et Marketplace
**Auteur:** Architecture Requiem
